<!DOCTYPE html>
<html lang="zh-CN">
</div>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>FastAPI + Vosk 实时语音转文字</title>
    <style>
        body {
            font-family: sans-serif;
            padding: 20px;
            display: flex;
            flex-direction: column;
            min-height: 95vh;
            margin: 0;
            background-color: #f4f4f4; 
            overflow: hidden;
        }

        h1 {
            text-align: center;
            margin-bottom: 20px;
            flex-shrink: 0;
        }

        .main-container {
            display: flex;
            flex-grow: 1;
            gap: 20px;
            width: 100%;
            max-width: 1400px;
            margin: 0 auto;
            overflow: hidden;
            height: 70vh; 
        }

        #digitalHumanArea {
            flex-basis: 65%;
            flex-shrink: 0;
            border: 2px dashed #ccc;
            min-height: 400px;
            display: flex;
            align-items: center;
            justify-content: center;
            color: #aaa;
            font-size: 1.2em;
            text-align: center;
            background-color: #b8b7b7;
            padding: 15px;
            box-sizing: border-box;
            overflow: hidden;
        }

        #speechInteractionWrapper {
            flex-basis: 35%;
            flex-grow: 1;
            display: flex;
            flex-direction: column;
            gap: 20px;
            min-width: 300px;
            overflow: hidden;
            height: 100%;
        }

        #speechRecognitionArea, #controls-file {
            padding: 20px;
            border: 1px solid #ddd;
            border-radius: 8px;
            background-color: #fff;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
            width: 100%;
            box-sizing: border-box;
            display: flex;
            flex-direction: column;
            flex-grow: 1;
            min-height: 0;
            height: 100%;
        }

        #transcript {
            margin-top: 10px;
            padding: 15px;
            border: 1px solid #ccc;
            min-height: 100px;
            overflow-y: auto;
            scrollbar-width: thin;
            background-color: #f9f9f9;
            white-space: pre-wrap;
            border-radius: 4px;
            line-height: 1.6;
            flex-grow: 1;
            display: flex;
            flex-direction: column;
            gap: 10px;
            height: auto; 
        }


        #controls {
            display: flex;
            align-items: center;
            gap: 10px;
            margin-bottom: 15px;
            flex-shrink: 0;
        }

        #controls button {
            padding: 10px 15px;
            font-size: 16px;
            cursor: pointer;
        }

        #status-mic {
            margin-left: auto;
            font-style: italic;
            color: #555;
        }

        .upload-actions {
            display: flex;
            gap: 8px;
            margin-bottom: 10px;
            flex-shrink: 0;
        }

        .upload-actions input[type="file"],        

        .upload-actions button {
            max-width: 100%;
            box-sizing: border-box;
        }

        .upload-status {
            margin-top: 10px;
            font-size: 0.9em;
            color: #555;
            word-break: break-all;
            flex-shrink: 0;
        }

        #file-info {
            margin-right: 10px;
            display: inline-block;
        }

        #transcript p:first-child {
            color: #888;
            font-style: italic;
            text-align: center;
        }
        
        /* Initial Prompt Message */
        #transcript p.initial-prompt {
            color: #888;
            font-style: italic;
            text-align: center;
            margin: auto; /* Center vertically and horizontally if alone */
            padding: 20px;
        }
        /* General Message Bubble Style */
        .message-bubble {
            padding: 8px 12px;
            border-radius: 15px;
            max-width: 85%; /* Max width of a bubble */
            word-wrap: break-word; /* Wrap long words */
            line-height: 1.4;
            box-shadow: 0 1px 2px rgba(0,0,0,0.1);
        }

        .message-assistant {
            background-color: #74c727; /* Light blue background */
            color: #333;
            border: 1px solid #74c727;
            align-self: flex-start; /* Align to the left */
            border-bottom-left-radius: 3px; /* Make it look like a speech bubble */
        }

        /* Style for Finalized User Messages (Recognized Speech) */
        .message-final {
            background-color: #e1f5fe; /* Light blue background */
            color: #333;
            border: 1px solid #b3e5fc;
            align-self: flex-start; /* Align to the left */
            border-bottom-left-radius: 3px; /* Make it look like a speech bubble */
        }

        /* Style for Partial (In-progress) Messages */
        .message-partial {
            background-color: #f0f0f0; /* Lighter grey background */
            color: #666;
            font-style: italic;
            border: 1px solid #e0e0e0;
            align-self: flex-start; /* Align to the left */
            border-bottom-left-radius: 3px;
            opacity: 0.9;
        }

         /* Style for File Upload Results */
        .message-file {
            background-color: #e8f5e9; /* Light green background */
            color: #1b5e20;
            border: 1px solid #c8e6c9;
            align-self: flex-start; /* Align to the left */
            border-bottom-left-radius: 3px;
            white-space: pre-wrap; /* Preserve line breaks from result */
            font-family: monospace; /* Optional: Use monospace for file content */
        }
        .message-file strong { /* Style the filename part */
             display: block;
             margin-bottom: 5px;
             font-family: sans-serif;
             color: #333;
             font-weight: bold;
             font-size: 0.9em;
        }

        /* Style for Error Messages */
        .message-error {
            background-color: #ffebee; /* Light red background */
            color: #c62828;
            border: 1px solid #ffcdd2;
            align-self: center; /* Center error messages */
            text-align: center;
            font-weight: bold;
            width: 90%;
            box-sizing: border-box;
        }

        .partial {
            color: #888;
            opacity: 0.8;
        }

        .section-title {
            font-weight: bold;
            margin-bottom: 10px;
            display: block;
        }

        .status {
            font-style: italic;
            color: #555;
        }
    </style>
</head>
<body>

<h1>实时语音转文字与数字人交互</h1>

<div class="main-container">
    <!-- 左侧：数字人区域 -->
    <div id="digitalHumanArea">
        <video id="dh-video" muted autoplay style="width:100%; height:auto;"></video>
        <!-- <img src="your-image.jpg" alt="数字人" style="max-width: 100%; max-height: 100%;"> -->
    </div>

    <!-- 右侧：语音交互区域 -->
    <div id="speechInteractionWrapper">
        <!-- 麦克风识别 -->
        <div id="speechRecognitionArea">
            <div id="controls">
                <button id="startButton">开始识别</button>
                <button id="stopButton" disabled>停止识别</button>
                <button id="cleanButton" >清除内容</button>
                <span id="status-mic">状态：未连接</span>
            </div>

            <div class="upload-actions">
                <input type="file" id="audioFileInput" accept="audio/*">
                <button id="uploadButton">上传并识别</button>
            </div>
            
            <div class="upload-status">
                <span id="file-info"></span>
                <span id="status-file" class="status"></span>
            </div>
           
            <div id="transcript">
                <p class="initial-prompt">识别结果将显示在这里...</p>
            </div>
        </div>
    </div>
</div>

<script src="https://cdn.jsdelivr.net/npm/hls.js@latest"></script>
<script>
    // JavaScript 部分保持不变，因为它通过 ID 选择元素，
    // 并且布局的改变不影响其功能逻辑。
    const startButton = document.getElementById('startButton');
    const stopButton = document.getElementById('stopButton');
    const cleanButton = document.getElementById('cleanButton');
    const statusDiv = document.getElementById('status-mic');
    const audioFileInput = document.getElementById('audioFileInput');
    const uploadButton = document.getElementById('uploadButton');
    const statusFile = document.getElementById('status-file');
    const fileInfo = document.getElementById('file-info');

    const transcriptDiv = document.getElementById('transcript');

    let websocket;
    let audioContext;
    let scriptProcessor; // 或者 AudioWorkletNode
    let mediaStream;
    let isRecording = false;
    let partialTranscriptElement = null; // 用于跟踪当前的部分结果元素

    // --- WebSocket 地址 ---
    const wsUrl = `ws://${window.location.host}/mic`;
    const llmWsUrl  = `ws://${window.location.host}/llm_stream`;

    // --- 音频参数 ---
    const TARGET_SAMPLE_RATE = 16000;
    const BUFFER_SIZE = 4096;
    
    // --- Helper: Scroll transcript to bottom ---
    function scrollTranscriptToEnd() {
        setTimeout(() => {
            transcriptDiv.scrollTop = transcriptDiv.scrollHeight;
        }, 0);
    }

     // --- Helper: Add a message bubble to the transcript ---
     function addMessageBubble(text, type = 'final', optionalFileName = null) {
        // Remove initial prompt if it exists
        const initialPrompt = transcriptDiv.querySelector('p.initial-prompt');
        if (initialPrompt) {
            initialPrompt.remove();
        }

        const messageDiv = document.createElement('div');
        messageDiv.classList.add('message-bubble');

        switch (type) {
            case 'partial':
                messageDiv.classList.add('message-partial');
                messageDiv.textContent = text ? text + '...' : '...'; // Add ellipsis
                currentPartialMessageElement = messageDiv; // Store reference
                break;
            case 'file':
                 messageDiv.classList.add('message-file');
                 const fileNameStrong = document.createElement('strong');
                 fileNameStrong.textContent = `文件 (${optionalFileName || 'Unknown File'}):`;
                 messageDiv.appendChild(fileNameStrong);
                 messageDiv.appendChild(document.createTextNode(text)); // Add text node for transcription
                 break;
            case 'error':
                messageDiv.classList.add('message-error');
                messageDiv.textContent = text;
                break;
            case 'llm_answer':
                messageDiv.classList.add('message-assistant');
                messageDiv.textContent = `assistant: ${text}`;
                messageDiv.textContent = text;
                break;
            case 'final':
            default:
                messageDiv.classList.add('message-final');
                messageDiv.textContent = text + '。'; // Add punctuation
                break;
        }

        transcriptDiv.appendChild(messageDiv);
        scrollTranscriptToEnd(); // Scroll after adding
        return messageDiv; // Return the created element if needed
    }

    // --- 开始识别 ---
    startButton.onclick = async () => {
        if (isRecording) return;
        statusDiv.textContent = '状态：正在请求麦克风权限...';
        // 清空转录区域，保留初始提示结构
        //transcriptDiv.innerHTML = '<p>识别结果将显示在这里...</p>';
        partialTranscriptElement = null;

        try {
            mediaStream = await navigator.mediaDevices.getUserMedia({
                audio: {
                    echoCancellation: true,
                    noiseSuppression: true,
                },
                video: false
            });

            statusDiv.textContent = '状态：已获取麦克风权限，正在连接服务器...';

            websocket = new WebSocket(wsUrl);

            websocket.onopen = () => {
                statusDiv.textContent = '状态：连接成功，正在识别...';
                isRecording = true;
                startButton.disabled = true;
                stopButton.disabled = false;
                startAudioProcessing(); // 开始处理音频
            };

            websocket.onmessage = (event) => {
                try {
                    const result = JSON.parse(event.data);
                    if (result.error) {
                        console.error("服务器错误:", result.error);
                        statusDiv.textContent = `状态：错误 - ${result.error}`;
                        stopRecording();
                        return;
                    }
                    updateTranscript(result);
                } catch (e) {
                    console.error("解析服务器消息失败:", e);
                }
            };

            websocket.onerror = (event) => {
                console.error("WebSocket 错误:", event);
                statusDiv.textContent = '状态：WebSocket 连接错误';
                isRecording = false;
                cleanupAudio();
                startButton.disabled = false;
                stopButton.disabled = true;
            };

            websocket.onclose = (event) => {
                console.log("WebSocket 连接关闭:", event.code, event.reason);
                if (isRecording) { // 避免在手动停止时显示“已断开”
                    statusDiv.textContent = '状态：连接已断开';
                }
                isRecording = false;
                cleanupAudio();
                startButton.disabled = false;
                stopButton.disabled = true;
                partialTranscriptElement = null;
            };

        } catch (err) {
            console.error('获取麦克风或连接 WebSocket 失败:', err);
            statusDiv.textContent = `状态：错误 - ${err.message}`;
            cleanupAudio();
            isRecording = false;
            startButton.disabled = false;
            stopButton.disabled = true;
        }
    };

    // --- 停止识别 ---
    stopButton.onclick = () => {
        stopRecording();
    };

    cleanButton.onclick = () => {
        transcriptDiv.innerHTML = '';
        currentPartialMessageElement = null;
    }

    audioFileInput.onchange = () => {
        const file = audioFileInput.files[0];
        if (file) {
            fileInfo.textContent = `已选择: ${file.name} (${(file.size / 1024 / 1024).toFixed(2)} MB)`;
             statusFile.textContent = ''; // Clear previous status/error
             statusFile.classList.remove('error');
        } else {
            fileInfo.textContent = '';
        }
    };

    uploadButton.onclick = async () => {
        const file = audioFileInput.files[0];
        if (!file) {
            alert('请先选择一个音频文件！');
            return;
        }

        const formData = new FormData();
        formData.append('audio_file', file);

        const processingMessage = addMessageBubble(`正在处理文件: ${file.name}...`, 'status', true); 
        scrollTranscriptToEnd();

        // Disable buttons during upload
        uploadButton.disabled = true;
        audioFileInput.disabled = true;
        statusFile.textContent = '状态: 正在上传和处理...';
        statusFile.classList.remove('error');
        // Clear previous output OR indicate new process starting
        <!-- transcriptDiv.textContent = '正在处理上传的文件...'; // Indicate processing -->

        try {
            const response = await fetch('/upload_audio/', {
                method: 'POST',
                body: formData
            });

            if (processingMessage) {
                processingMessage.remove();
            }

            if (!response.ok) {
                let errorMsg = `HTTP 错误: ${response.status}`;
                try { // Try to get detailed error from server response body
                    const errData = await response.json();
                    errorMsg += ` - ${errData.detail || '未知错误'}`;
                } catch (e) { /* Ignore if response body is not JSON */ }
                throw new Error(errorMsg);
            }

            const data = await response.json();

            if (data && data.transcription) {
                // 不要覆盖 transcriptDiv.textContent 或 innerHTML
                // transcriptDiv.textContent = result.text; // <--- 删除或注释掉这样的旧代码
    
                // 使用 addMessageBubble 添加结果到聊天框
                addMessageBubble(data.transcription ,'final'); // 添加为最终消息
    
                // 添加滚动到底部的调用
                scrollTranscriptToEnd();
    
            } else {
                 addMessageBubble("从文件未识别到文本", "status");
                 scrollTranscriptToEnd();
            }

            // ** 更新统一的输出区域 **
            // Replace the content with the file's transcription result
            //transcriptDiv.textContent = `文件 (${file.name}) 识别结果:\n--------------------------\n${data.transcription}`;
            statusFile.textContent = '状态: 处理完成！';
            console.log('File transcription:', data.transcription);

        } catch (error) {
            console.error('Error uploading or processing file:', error);
            statusFile.textContent = `错误: ${error.message}`;
             statusFile.classList.add('error');
             // Show error in the main output area as well
             transcriptDiv.textContent = `文件处理出错: ${error.message}`;
        } finally {
            // Re-enable buttons
            uploadButton.disabled = false;
            audioFileInput.disabled = false;
            // Optionally clear file input for next upload?
            // audioFileInput.value = null;
            // fileInfo.textContent = '';
        }
    };

    // --- 停止录音和连接的函数 ---
    function stopRecording() {
        if (!isRecording) return;
        isRecording = false;
        statusDiv.textContent = '状态：已停止';
        startButton.disabled = false;
        stopButton.disabled = true;

        if (websocket && websocket.readyState === WebSocket.OPEN) {
            // 可以在关闭前发送一个特殊的“结束”信号（如果后端需要）
            // websocket.send(JSON.stringify({ command: "stop" }));
            websocket.close();
        }
        websocket = null;

        cleanupAudio();
    }

    // --- 开始处理音频 (仍使用 ScriptProcessorNode) ---
    function startAudioProcessing() {
        audioContext = new (window.AudioContext || window.webkitAudioContext)();

        const sourceSampleRate = audioContext.sampleRate;
        console.log(`音频上下文采样率: ${sourceSampleRate} Hz`);

        // 建议在实际使用中切换到 AudioWorklet
        if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
             console.error("浏览器不支持 getUserMedia");
             statusDiv.textContent = '状态：错误 - 浏览器不支持麦克风输入';
             stopRecording();
             return;
        }

        const source = audioContext.createMediaStreamSource(mediaStream);

        // 注意: ScriptProcessorNode 已被废弃
        scriptProcessor = audioContext.createScriptProcessor(BUFFER_SIZE, 1, 1);

        scriptProcessor.onaudioprocess = (event) => {
            if (!isRecording || !websocket || websocket.readyState !== WebSocket.OPEN) {
                return;
            }

            const inputData = event.inputBuffer.getChannelData(0);
            const pcm16Buffer = convertFloat32ToInt16(inputData, sourceSampleRate, TARGET_SAMPLE_RATE);
            websocket.send(pcm16Buffer);
        };

        source.connect(scriptProcessor);
        scriptProcessor.connect(audioContext.destination); // 必需，否则可能不触发 process
    }

    // --- 清理音频资源 ---
    function cleanupAudio() {
        if (scriptProcessor) {
            scriptProcessor.disconnect();
            scriptProcessor.onaudioprocess = null;
            scriptProcessor = null;
        }
        // 检查 audioContext 状态，避免在已关闭时再次关闭
        if (audioContext && audioContext.state !== 'closed') {
            audioContext.close().catch(e => console.warn("关闭 AudioContext 时出错:", e));
        }
        audioContext = null; // 清除引用
        if (mediaStream) {
            mediaStream.getTracks().forEach(track => track.stop());
            mediaStream = null;
        }
        console.log("音频资源已清理");
    }

   // --- 更新转录文本显示 ---
   function updateTranscript(result) {
    // 先检查是否存在明确的错误字段 (兼容旧格式或特定错误上报)
    if (result.error) {
        console.error("服务器明确报告错误:", result.error);
        addMessageBubble(`错误: ${result.error}`, 'error');
        // 可以选择根据错误类型决定是否停止录音等操作
        // stopRecording();
        return; // 错误处理完毕，直接返回
    }

    // 根据消息类型调用 addMessageBubble
    switch (result.type) {
        case 'final':
            const finalText = result.text ? result.text.trim() : '';
            if (finalText) { // 仅在有文本时添加
                addMessageBubble(finalText, 'final');
            } else if (currentPartialMessageElement) {
                // 如果收到空的 final 且存在 partial，则移除空的 partial
                currentPartialMessageElement.remove();
                currentPartialMessageElement = null;
            }
            break;

        case 'partial':
            const partialText = result.text ? result.text.trim() : null; // 假设部分结果也在 .text 中
            // const partialText = result.partial ? result.partial.trim() : null; // 或者如果部分结果仍在 .partial 中
            if (partialText) {
                addMessageBubble(partialText, 'partial');
            } else if (currentPartialMessageElement) {
                 // 如果收到空的 partial 且存在 partial 元素，可以选择移除或保留
                 // currentPartialMessageElement.remove();
                 // currentPartialMessageElement = null;
                 // 或者保持不动，等 final 结果来覆盖或超时处理
            }
            break;

        case 'llm_answer':
            const answerText = result.text ? result.text.trim() : '';
            if (answerText) {
                addMessageBubble(answerText, 'llm_answer');
            }
            break;

        case 'error': // 处理由 onmessage 的 catch 或服务器直接发送的 error 类型
             const errorText = result.text || result.message || '未知错误'; // 尝试获取错误文本
             addMessageBubble(`错误: ${errorText}`, 'error');
             break;

        default:
            // 处理未知类型或没有明确文本的消息
            // 也许可以记录一个警告，或者根据情况决定是否显示什么
            console.warn("收到未知或无有效内容的消息类型:", result);
            // 如果当前有部分消息，收到未知消息可能意味着结束，可以考虑固化或移除
            if (currentPartialMessageElement) {
                 const currentText = currentPartialMessageElement.textContent.replace('你 (输入中...): ','').replace(/\.\.\.$/, '').trim();
                 if (currentText) {
                     currentPartialMessageElement.textContent = `你: ${currentText}`; // 改为最终样式
                     currentPartialMessageElement.classList.remove('message-partial');
                     currentPartialMessageElement.classList.add('message-final');
                 } else {
                     currentPartialMessageElement.remove();
                 }
                 currentPartialMessageElement = null;
            }
            break;
    }
}


    // --- 音频格式转换和重采样函数 ---
    function convertFloat32ToInt16(buffer, sourceSr, targetSr) {
        let outputBuffer;
        let sampleRatio = sourceSr / targetSr;
        let newLength = Math.round(buffer.length / sampleRatio);
        outputBuffer = new Int16Array(newLength);
        let offsetResult = 0;
        let offsetBuffer = 0;

        while (offsetResult < newLength) {
            let nextOffsetBuffer = Math.round((offsetResult + 1) * sampleRatio);
            let accum = 0, count = 0;
            for (let i = offsetBuffer; i < nextOffsetBuffer && i < buffer.length; i++) {
                accum += buffer[i];
                count++;
            }
            // Clamp and convert value
            let value = Math.max(-1, Math.min(1, count > 0 ? accum / count : 0));
             // Convert to 16-bit PCM
            outputBuffer[offsetResult] = value < 0 ? value * 0x8000 : value * 0x7FFF;
            offsetResult++;
            offsetBuffer = nextOffsetBuffer;
        }
        return outputBuffer.buffer; // 返回 ArrayBuffer
    }

    function connectLLMStream() {
        if (llmWebsocket && llmWebsocket.readyState === WebSocket.OPEN) {
            console.log("LLM Stream WebSocket 已连接."); // LLM Stream WebSocket already connected.
            uploadButton.disabled = false; // Enable upload button if connected
            return; // Already connected
        }

        console.log("正在连接 LLM Stream WebSocket..."); // Connecting LLM Stream WebSocket...
        llmWebsocket = new WebSocket(llmWsUrl);

        llmWebsocket.onopen = () => {
            console.log("LLM Stream WebSocket 连接成功."); // LLM Stream WebSocket connection successful.
             // Enable upload button only when LLM stream is connected
             uploadButton.disabled = false;
             statusFile.textContent = '状态: 已连接，可上传文件'; // Indicate ready state for file upload
        };

        llmWebsocket.onmessage = (event) => {
            try {
                const result = JSON.parse(event.data);
                console.log("LLM Stream 收到消息:", result); // LLM Stream received message
                updateTranscript(result); // Process LLM answers or file results

                 // If it was a file result, update file status
                 if (result.type === 'file') {
                     statusFile.textContent = '状态: 文件处理完成!';
                     statusFile.classList.remove('error');
                      // Re-enable upload button after processing is fully done
                      uploadButton.disabled = false;
                      audioFileInput.disabled = false;
                 }

            } catch (e) {
                console.error("解析 LLM Stream 消息失败:", e, "原始数据:", event.data); // Failed to parse LLM Stream message
                updateTranscript({ type: 'error', text: '无法解析 LLM Stream 响应' }); // Cannot parse LLM Stream response
            }
        };

        llmWebsocket.onerror = (event) => {
            console.error("LLM Stream WebSocket 错误:", event); // LLM Stream WebSocket error
            addMessageBubble("LLM Stream 连接错误", "error");
             uploadButton.disabled = true; // Disable upload on error
             statusFile.textContent = '状态: LLM Stream 连接错误';
             statusFile.classList.add('error');
        };

        llmWebsocket.onclose = (event) => {
            console.log("LLM Stream WebSocket 关闭:", event.code, event.reason); // LLM Stream WebSocket closed
            addMessageBubble("LLM Stream 连接已断开", "status");
            llmWebsocket = null; // Clear reference
             uploadButton.disabled = true; // Disable upload on close
             statusFile.textContent = '状态: LLM Stream 连接已断开';
        };
    }

    document.addEventListener('DOMContentLoaded', () => {


        const video = document.getElementById('dh-video');
        const hlsUrl = '/live/stream.m3u8'; // 必须与FastAPI路由匹配
        
        if (Hls.isSupported()) {
            const hls = new Hls();
            hls.loadSource(hlsUrl);
            hls.attachMedia(video);
            hls.on(Hls.Events.MANIFEST_PARSED, () => {
                video.play();
            });
        } else if (video.canPlayType('application/vnd.apple.mpegurl')) {
            // Safari原生支持
            video.src = hlsUrl;
            video.addEventListener('loadedmetadata', () => {
                video.play();
            });
        } else {
            console.error("浏览器不支持HLS播放");
        }
    });
</script>

</body>
</html>